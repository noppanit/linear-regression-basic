{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Introduction\n",
    "This is going to be a very basic examples of Linear Regression. Basically, we have generated data of total amount of meals and tips.\n",
    "We would like to use this historical data to predict the tip for any given amount of bill.\n",
    "\n",
    "The data is going to be perfect because I just want to show how easy it is to do Linear Regression.\n",
    "\n",
    "Best example so far I have found to calculate Linear Regression.\n",
    "\n",
    "http://onlinestatbook.com/2/regression/intro.html\n",
    "\n",
    "http://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/\n",
    "\n",
    "https://github.com/mattnedrich/GradientDescentExample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import collections\n",
    "import time\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data\n",
    "We are going to generate a 1000 samples of random number between \\$0 - \\$100. And let's say that each meal the customer tips 10% of the amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_bills = np.random.randint(100, size=1000)\n",
    "tips = total_bills * 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easier if we select the correct X and Y axis. Usually, The Y axis would be the value we want to predict and X would be the feed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd.Series(tips, name='tips')\n",
    "y = pd.Series(total_bills, name='total_bills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([x, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEQCAYAAABfiGi4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f39a438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind='scatter', x='total_bills', y='tips');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the graph that there's a strong correlation between amount of tip and meal. Now we want to calculate the regression line. We need the slope and intercept to feed in the formula. Y = MX + C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope is 0.100000 and intercept is 1.7763568394e-15\n"
     ]
    }
   ],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x=total_bills, y=tips)\n",
    "print(\"slope is %f and intercept is %s\" % (slope,intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say if the customer spent $70 how much the customer will tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_tips = (slope * 70) + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer will leave the tip of $7.000000\n"
     ]
    }
   ],
   "source": [
    "print('The customer will leave the tip of $%f' % predicted_tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large dataset\n",
    "\n",
    "Now let's have a look at large dataset. Let's see how our Linear Regression performs. I'm going to create 100 million datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "large_total_bills = np.random.randint(10000, size=100000000)\n",
    "large_tips = total_bills * 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer will leave the tip of $499.961690\n",
      "The time spent is 11.000000 seconds\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x=large_total_bills, y=large_tips)\n",
    "predicted_tips = (slope * 700) + intercept\n",
    "\n",
    "later = time.time()\n",
    "difference = int(later - now) \n",
    "print('The customer will leave the tip of $%f' % predicted_tips)\n",
    "print('The time spent is %f seconds' % difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Decent\n",
    "\n",
    "Now, I'm going to use Gradient Decent to find the fitted line. It's been known that Gradient Decent is better for large dataset. Let's see how well it performs. I'm going to use the code example from\n",
    "https://github.com/mattnedrich/GradientDescentExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error_for_line_given_points (b, m, points):\n",
    "    totalError = 0\n",
    "    for i in range(0, len(points)):\n",
    "        totalError += (points[i].y - (m * points[i].x + b)) ** 2\n",
    "    return totalError / float(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient(b_current, m_current, points, learningRate):\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        b_gradient += -(2/N) * (points[i].y - ((m_current*points[i].x) + b_current))\n",
    "        m_gradient += -(2/N) * points[i].x * (points[i].y - ((m_current * points[i].x) + b_current))\n",
    "    new_b = b_current - (learningRate * b_gradient)\n",
    "    new_m = m_current - (learningRate * m_gradient)\n",
    "    return [new_b, new_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_runner(points, starting_b, starting_m, learning_rate, num_iterations):\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "    for i in range(num_iterations):\n",
    "        b, m = step_gradient(b, m, points, learning_rate)\n",
    "    return [b, m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at b = 0, m = 0, error = 33.086309999999955\n",
      "Running...\n",
      "After 1000 iterations b = 0.001432728484911941, m = 0.09997841844411902, error = 5.119034280329996e-07\n"
     ]
    }
   ],
   "source": [
    "class point:\n",
    "    def __init__(self,x,y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        \n",
    "x = np.random.randint(100, size=1000)\n",
    "y = x * 0.10\n",
    "\n",
    "np.column_stack((x,y))\n",
    "\n",
    "points = []\n",
    "collections.namedtuple('Point', ['x', 'y'])\n",
    "for i in range(len(x)):\n",
    "        points.append(point(x[i],y[i]))\n",
    "\n",
    "learning_rate = 0.0001\n",
    "initial_b = 0 # initial y-intercept guess\n",
    "initial_m = 0 # initial slope guess\n",
    "num_iterations = 1000\n",
    "print(\"Starting gradient descent at b = {0}, m = {1}, error = {2}\".format(initial_b, initial_m, compute_error_for_line_given_points(initial_b, initial_m, points)))\n",
    "print(\"Running...\")\n",
    "[b, m] = gradient_descent_runner(points, initial_b, initial_m, learning_rate, num_iterations)\n",
    "print(\"After {0} iterations b = {1}, m = {2}, error = {3}\".format(num_iterations, b, m, compute_error_for_line_given_points(b, m, points)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see after 1000 interations how close are we. Pretty close I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9999220195732432"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_predicted_tips = (m * 70) + b\n",
    "gradient_predicted_tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you really don't need to write that on your own as Scikit provides that for you already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for SGDRegressor is 313 seconds\n",
      "slope is 0.100000 and intercept is 5.96178570559e-07\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(100, size=100000000)\n",
    "y = x * 0.10\n",
    "\n",
    "x = x[:,None]\n",
    "\n",
    "now = time.time()\n",
    "\n",
    "clf = SGDRegressor()\n",
    "clf.fit(x, y)\n",
    "\n",
    "later = time.time()\n",
    "difference = int(later - now) \n",
    "print(\"Time spent for SGDRegressor is %d seconds\" % difference)    \n",
    "print(\"slope is %f and intercept is %s\" % (clf.coef_, clf.intercept_[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.99999978])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(70) # How much tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
